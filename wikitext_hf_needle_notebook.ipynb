{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "luyfKrR82JRh",
      "metadata": {
        "id": "luyfKrR82JRh"
      },
      "source": [
        "# WikiText-103 with Hugging Face + Needle\n",
        "\n",
        "This notebook does the following:\n",
        "\n",
        "1. Uses **Hugging Face `datasets`** to download WikiText-103 (`wikitext-103-v1`).\n",
        "2. Writes the splits into `wiki.train.tokens`, `wiki.valid.tokens`, `wiki.test.tokens` in a local folder.\n",
        "3. Uses your existing **`needle.data.datasets.wikitext_dataset`** `Corpus` + `batchify` utilities.\n",
        "4. Trains and evaluates a language model using your **`train_wikitext`** and **`evaluate_wikitext`** functions from `apps/simple_ml.py`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e12e4d33",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e12e4d33",
        "outputId": "c721614b-4ab7-4b11-e3b8-e9a8408e1b73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/10714/project\n",
            "Collecting pybind11\n",
            "  Downloading pybind11-3.0.1-py3-none-any.whl.metadata (10.0 kB)\n",
            "Downloading pybind11-3.0.1-py3-none-any.whl (293 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.6/293.6 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pybind11\n",
            "Successfully installed pybind11-3.0.1\n"
          ]
        }
      ],
      "source": [
        "# Code to set up the assignment\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "%cd /content/drive/MyDrive/10714/project\n",
        "!pip3 install pybind11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "dLIvPQJg65F0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLIvPQJg65F0",
        "outputId": "cff5a527-ce39-4ba1-d2dc-d862800630fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0mCMake Deprecation Warning at CMakeLists.txt:1 (cmake_minimum_required):\n",
            "  Compatibility with CMake < 3.10 will be removed from a future version of\n",
            "  CMake.\n",
            "\n",
            "  Update the VERSION argument <min> value.  Or, use the <min>...<max> syntax\n",
            "  to tell CMake that the project requires at least <min> but has been updated\n",
            "  to work with policies introduced by <max> or earlier.\n",
            "\n",
            "\u001b[0m\n",
            "-- Found pybind11: /usr/local/lib/python3.12/dist-packages/pybind11/include (found version \"3.0.1\")\n",
            "-- Found cuda, building cuda backend\n",
            "Fri Nov 28 04:26:59 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   51C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "-- Autodetected CUDA architecture(s):  8.0\n",
            "-- Configuring done (5.8s)\n",
            "-- Generating done (12.3s)\n",
            "-- Build files have been written to: /content/drive/MyDrive/10714/project/build\n",
            "make[1]: Entering directory '/content/drive/MyDrive/10714/project/build'\n",
            "make[2]: Entering directory '/content/drive/MyDrive/10714/project/build'\n",
            "make[3]: Entering directory '/content/drive/MyDrive/10714/project/build'\n",
            "make[3]: Leaving directory '/content/drive/MyDrive/10714/project/build'\n",
            "make[3]: Entering directory '/content/drive/MyDrive/10714/project/build'\n",
            "[-25%] \u001b[32mBuilding CXX object CMakeFiles/ndarray_backend_cpu.dir/src/ndarray_backend_cpu.cc.o\u001b[0m\n",
            "[  0%] \u001b[32m\u001b[1mLinking CXX shared module /content/drive/MyDrive/10714/project/python/needle/backend_ndarray/ndarray_backend_cpu.cpython-312-x86_64-linux-gnu.so\u001b[0m\n",
            "make[3]: Leaving directory '/content/drive/MyDrive/10714/project/build'\n",
            "[  0%] Built target ndarray_backend_cpu\n",
            "make[3]: Entering directory '/content/drive/MyDrive/10714/project/build'\n",
            "[ 25%] \u001b[34m\u001b[1mBuilding NVCC (Device) object CMakeFiles/ndarray_backend_cuda.dir/src/ndarray_backend_cuda_generated_ndarray_backend_cuda.cu.o\u001b[0m\n",
            "make[3]: Leaving directory '/content/drive/MyDrive/10714/project/build'\n",
            "make[3]: Entering directory '/content/drive/MyDrive/10714/project/build'\n",
            "[ 50%] \u001b[32m\u001b[1mLinking CXX shared module /content/drive/MyDrive/10714/project/python/needle/backend_ndarray/ndarray_backend_cuda.cpython-312-x86_64-linux-gnu.so\u001b[0m\n",
            "make[3]: Leaving directory '/content/drive/MyDrive/10714/project/build'\n",
            "[ 50%] Built target ndarray_backend_cuda\n",
            "make[2]: Leaving directory '/content/drive/MyDrive/10714/project/build'\n",
            "make[1]: Leaving directory '/content/drive/MyDrive/10714/project/build'\n"
          ]
        }
      ],
      "source": [
        "!make"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "DAPS0tLK68dC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAPS0tLK68dC",
        "outputId": "272da8d9-b50a-4202-e60e-0282deab4e7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: PYTHONPATH=./python\n",
            "env: NEEDLE_BACKEND=nd\n"
          ]
        }
      ],
      "source": [
        "%set_env PYTHONPATH ./python\n",
        "%set_env NEEDLE_BACKEND nd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "x51jp-tL6-YC",
      "metadata": {
        "id": "x51jp-tL6-YC"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('./python')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "26a720a6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26a720a6",
        "outputId": "d350371d-e9de-49c2-fdaa-9e3186306da8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using needle backend\n"
          ]
        }
      ],
      "source": [
        "import os, math, time, sys\n",
        "import numpy as np\n",
        "\n",
        "# Make `python/` visible as a package root\n",
        "sys.path.append(\"python\")\n",
        "sys.path.append(\"apps\")\n",
        "\n",
        "import needle as ndl\n",
        "import needle.nn as nn\n",
        "from needle import Tensor\n",
        "\n",
        "# Training / evaluation helpers\n",
        "from apps.simple_ml import train_wikitext, evaluate_wikitext\n",
        "\n",
        "# Your language model definition (adjust class / args as needed)\n",
        "# from apps.models import LanguageModel  # change if your LM class has a different name\n",
        "from needle.nn.nn_lm import LanguageModel\n",
        "\n",
        "# Your WikiText dataset helpers\n",
        "from needle.data.datasets import wikitext_dataset as wt\n",
        "\n",
        "# device = ndl.cpu()  # or ndl.cuda() if you wired up a GPU backend\n",
        "device = ndl.cuda()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fZNZ6EA32JRj",
      "metadata": {
        "id": "fZNZ6EA32JRj"
      },
      "source": [
        "## Download WikiText-103 using Hugging Face `datasets`\n",
        "\n",
        "This defines a small helper that\n",
        "\n",
        "- calls `load_dataset(\"wikitext\", \"wikitext-103-v1\")`\n",
        "- writes `wiki.train.tokens`, `wiki.valid.tokens`, `wiki.test.tokens`\n",
        "  into `data_dir`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "0b1htkc-2JRj",
      "metadata": {
        "id": "0b1htkc-2JRj"
      },
      "outputs": [],
      "source": [
        "def download_wikitext103_hf(data_dir: str = \"./wikitext-103\", overwrite: bool = False) -> str:\n",
        "    \"\"\"Download WikiText-103 via Hugging Face `datasets`.\n",
        "\n",
        "    Creates three files in `data_dir`:\n",
        "        - wiki.train.tokens\n",
        "        - wiki.valid.tokens\n",
        "        - wiki.test.tokens\n",
        "\n",
        "    Returns:\n",
        "        data_dir (str): directory containing the .tokens files.\n",
        "    \"\"\"\n",
        "    os.makedirs(data_dir, exist_ok=True)\n",
        "\n",
        "    train_f = os.path.join(data_dir, \"wiki.train.tokens\")\n",
        "    valid_f = os.path.join(data_dir, \"wiki.valid.tokens\")\n",
        "    test_f  = os.path.join(data_dir, \"wiki.test.tokens\")\n",
        "\n",
        "    if (not overwrite\n",
        "        and os.path.exists(train_f)\n",
        "        and os.path.exists(valid_f)\n",
        "        and os.path.exists(test_f)):\n",
        "        print(f\"[wikitext] Files already exist in {data_dir}, skipping download.\")\n",
        "        return data_dir\n",
        "\n",
        "    try:\n",
        "        from datasets import load_dataset\n",
        "    except ImportError as e:\n",
        "        raise RuntimeError(\n",
        "            \"Hugging Face `datasets` is not installed. \"\n",
        "            \"Install it with `pip install datasets`.\"\n",
        "        ) from e\n",
        "\n",
        "    print(\"[wikitext] Downloading WikiText-103 via Hugging Face datasets...\")\n",
        "    ds = load_dataset(\"wikitext\", \"wikitext-103-v1\")\n",
        "\n",
        "    def _write_split(split_name: str, out_path: str):\n",
        "        with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            for row in ds[split_name]:\n",
        "                # HF can give None for empty lines\n",
        "                text = row[\"text\"] if row[\"text\"] is not None else \"\"\n",
        "                f.write(text.rstrip() + \"\\n\")\n",
        "\n",
        "    _write_split(\"train\", train_f)\n",
        "    _write_split(\"validation\", valid_f)\n",
        "    _write_split(\"test\", test_f)\n",
        "\n",
        "    print(f\"[wikitext] Saved splits to {data_dir}\")\n",
        "    return data_dir\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "y6hr0cNs2JRj",
      "metadata": {
        "id": "y6hr0cNs2JRj"
      },
      "source": [
        "## `Corpus` and batchify\n",
        "\n",
        "We now:\n",
        "\n",
        "1. Call the downloader (only downloads the first time).\n",
        "2. Use `wt.Corpus` + `wt.batchify` to get language-model training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "B9sMTYIF2JRj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9sMTYIF2JRj",
        "outputId": "8f420942-1241-4c1f-87fb-f3fbf933ac80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[wikitext] Files already exist in ./wikitext-103, skipping download.\n",
            "Vocab size: 267735\n",
            "Train data shape: (103227021, 1)\n",
            "Valid data shape: (217646, 1)\n",
            "Test  data shape: (245569, 1)\n"
          ]
        }
      ],
      "source": [
        "# Directory where .tokens files will live\n",
        "data_dir = \"./wikitext-103\"  # you can change this\n",
        "\n",
        "# 1) Download (does nothing if files already exist and overwrite=False)\n",
        "download_wikitext103_hf(data_dir, overwrite=False)\n",
        "\n",
        "# 2) Build Corpus\n",
        "# NOTE: adjust use_subword / vocab size to match your wikitext_dataset implementation.\n",
        "corpus = wt.Corpus(\n",
        "    data_dir,\n",
        "    max_lines=None,          # set to a small int to debug on fewer lines\n",
        "    use_subword=False,       # True if you added BPE/subword support there\n",
        ")\n",
        "\n",
        "vocab_size = corpus.vocab_size\n",
        "print(\"Vocab size:\", vocab_size)\n",
        "\n",
        "batch_size = 1\n",
        "\n",
        "train_data = wt.batchify(corpus.train, batch_size, device=device, dtype=\"float32\")\n",
        "valid_data = wt.batchify(corpus.valid, batch_size, device=device, dtype=\"float32\")\n",
        "test_data  = wt.batchify(corpus.test,  batch_size, device=device, dtype=\"float32\")\n",
        "\n",
        "print(\"Train data shape:\", train_data.shape)\n",
        "print(\"Valid data shape:\", valid_data.shape)\n",
        "print(\"Test  data shape:\", test_data.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qcF_ZJ9s2JRj",
      "metadata": {
        "id": "qcF_ZJ9s2JRj"
      },
      "source": [
        "## Language model\n",
        "\n",
        "We have a `LanguageModel` class in `apps/models.py` taking\n",
        "`vocab_size`, `embedding_size`, `hidden_size`, `num_layers`, `device`, `dtype`.\n",
        "\n",
        "Change the constructor / class name if your implementation differs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "oEVoAbc4_UAb",
      "metadata": {
        "id": "oEVoAbc4_UAb"
      },
      "outputs": [],
      "source": [
        "embedding_size = 512\n",
        "max_position_embeddings = 1024\n",
        "learnable_word_embeddings = True\n",
        "n_layers = 2\n",
        "block_type = \"Transformer\"\n",
        "hidden_size = 512\n",
        "num_head = 8\n",
        "dim_head = 64\n",
        "dropout = 0.1\n",
        "causal = True\n",
        "batch_first = True\n",
        "sequence_len = max_position_embeddings\n",
        "resid_dropout = 0.\n",
        "layer_norm_epsilon = 1e-5\n",
        "pad_vocab_size_multiple = 8\n",
        "label_smoothing = 0.\n",
        "tie_word_embeddings = True\n",
        "\n",
        "# num_experts = 4\n",
        "# topk = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "ftalERDC2JRj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftalERDC2JRj",
        "outputId": "43c44ef3-d276-45d9-db9e-007922143dd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<needle.nn.nn_lm.LanguageModel object at 0x796766c00740>\n"
          ]
        }
      ],
      "source": [
        "transformer_lm = LanguageModel(\n",
        "    embedding_size=embedding_size,\n",
        "    vocab_size=vocab_size,\n",
        "    max_position_embeddings=max_position_embeddings,\n",
        "    learnable_word_embeddings=learnable_word_embeddings,\n",
        "    n_layers=n_layers,\n",
        "    block_type=block_type,\n",
        "    hidden_size=hidden_size,\n",
        "    num_head=num_head,\n",
        "    dim_head=dim_head,\n",
        "    dropout=dropout,\n",
        "    causal=causal,\n",
        "    batch_first=batch_first,\n",
        "    sequence_len=sequence_len,\n",
        "    resid_dropout=resid_dropout,\n",
        "    layer_norm_epsilon=layer_norm_epsilon,\n",
        "    pad_vocab_size_multiple=pad_vocab_size_multiple,\n",
        "    label_smoothing=label_smoothing,\n",
        "    tie_word_embeddings=tie_word_embeddings,\n",
        "    device=device,\n",
        "    dtype=\"float32\",\n",
        ")\n",
        "\n",
        "print(transformer_lm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "IzfViKISDg1P",
      "metadata": {
        "id": "IzfViKISDg1P"
      },
      "outputs": [],
      "source": [
        "embedding_size = 512\n",
        "max_position_embeddings = 1024\n",
        "learnable_word_embeddings = True\n",
        "n_layers = 2\n",
        "block_type = \"TopkMoETransformer\"\n",
        "hidden_size = 512\n",
        "num_head = 8\n",
        "dim_head = 64\n",
        "dropout = 0.1\n",
        "causal = True\n",
        "batch_first = True\n",
        "sequence_len = max_position_embeddings\n",
        "resid_dropout = 0.\n",
        "layer_norm_epsilon = 1e-5\n",
        "pad_vocab_size_multiple = 8\n",
        "label_smoothing = 0.\n",
        "tie_word_embeddings = True\n",
        "\n",
        "num_experts = 4\n",
        "topk = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "LcsinvTTD6So",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcsinvTTD6So",
        "outputId": "57d2ca4f-87ea-4545-f2b7-bc2a00715126"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<needle.nn.nn_lm.LanguageModel object at 0x796766c5be60>\n"
          ]
        }
      ],
      "source": [
        "transformer_moe = LanguageModel(\n",
        "    embedding_size=embedding_size,\n",
        "    vocab_size=vocab_size,\n",
        "    max_position_embeddings=max_position_embeddings,\n",
        "    learnable_word_embeddings=learnable_word_embeddings,\n",
        "    n_layers=n_layers,\n",
        "    block_type=block_type,\n",
        "    hidden_size=hidden_size,\n",
        "    num_head=num_head,\n",
        "    dim_head=dim_head,\n",
        "    dropout=dropout,\n",
        "    causal=causal,\n",
        "    batch_first=batch_first,\n",
        "    sequence_len=sequence_len,\n",
        "    resid_dropout=resid_dropout,\n",
        "    layer_norm_epsilon=layer_norm_epsilon,\n",
        "    pad_vocab_size_multiple=pad_vocab_size_multiple,\n",
        "    label_smoothing=label_smoothing,\n",
        "    tie_word_embeddings=tie_word_embeddings,\n",
        "    device=device,\n",
        "    dtype=\"float32\",\n",
        "    num_experts=num_experts,\n",
        "    topk=topk\n",
        ")\n",
        "\n",
        "print(transformer_moe)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "h_tXCpI22JRj",
      "metadata": {
        "id": "h_tXCpI22JRj"
      },
      "source": [
        "## Train on WikiText-103 -- transformer_lm\n",
        "\n",
        "Call `train_wikitext` function from `apps/simple_ml.py`.\n",
        "Feel free to tweak `n_epochs`, `lr`, optimizer, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "NkCcd9dW2JRj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "NkCcd9dW2JRj",
        "outputId": "05699ad3-af9e-4730-b170-60c895c35b7d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training WikiText-103:   0%|          | 0/1 [06:00<?, ?it/s]\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "out of memory",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1715530282.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m train_acc, train_loss = train_wikitext(\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mtransformer_lm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/10714/project/apps/simple_ml.py\u001b[0m in \u001b[0;36mtrain_wikitext\u001b[0;34m(model, data, seq_len, n_epochs, optimizer, lr, weight_decay, loss_fn, clip, device, dtype)\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Training WikiText-103\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m         avg_acc, avg_loss = epoch_general_wikitext(\n\u001b[0m\u001b[1;32m    474\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn_instance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mclip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/10714/project/apps/simple_ml.py\u001b[0m in \u001b[0;36mepoch_general_wikitext\u001b[0;34m(data, model, seq_len, loss_fn, opt, clip, device, dtype)\u001b[0m\n\u001b[1;32m    436\u001b[0m                 \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0mavg_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtotal_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/10714/project/python/needle/optim.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;31m# update params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0;31m### END YOUR SOLUTION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/10714/project/python/needle/autograd.py\u001b[0m in \u001b[0;36m__sub__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__sub__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mneedle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEWiseAdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneedle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNegate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mneedle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAddScalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/10714/project/python/needle/autograd.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_from_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/10714/project/python/needle/autograd.py\u001b[0m in \u001b[0;36mmake_from_op\u001b[0;34m(op, inputs)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mLAZY_MODE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m             \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrealize_cached_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/10714/project/python/needle/autograd.py\u001b[0m in \u001b[0;36mdetach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;34m\"\"\"Create a new tensor that shares the data but detaches from the graph.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_const\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrealize_cached_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/10714/project/python/needle/autograd.py\u001b[0m in \u001b[0;36mrealize_cached_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcached_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;31m# note: data implicitly calls realized cached data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         self.cached_data = self.op.compute(\n\u001b[0m\u001b[1;32m    108\u001b[0m             \u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrealize_cached_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         )\n",
            "\u001b[0;32m/content/drive/MyDrive/10714/project/python/needle/ops/ops_mathematic.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self, a, b)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mEWiseAdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensorOp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNDArray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNDArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_grad\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/10714/project/python/needle/backend_ndarray/ndarray.py\u001b[0m in \u001b[0;36m__add__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__add__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"NDArray\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"NDArray\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m         return self.ewise_or_scalar(\n\u001b[0m\u001b[1;32m    484\u001b[0m             \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mewise_add\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar_add\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m         )\n",
            "\u001b[0;32m/content/drive/MyDrive/10714/project/python/needle/backend_ndarray/ndarray.py\u001b[0m in \u001b[0;36mewise_or_scalar\u001b[0;34m(self, other, ewise_func, scalar_func)\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[0mdepending\u001b[0m \u001b[0mon\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0;34m\"other\"\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0man\u001b[0m \u001b[0mNDArray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mscalar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m         \"\"\"\n\u001b[0;32m--> 474\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNDArray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNDArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"operation needs two equal-sized arrays\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/10714/project/python/needle/backend_ndarray/ndarray.py\u001b[0m in \u001b[0;36mmake\u001b[0;34m(shape, strides, device, handle, offset)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdefault_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m             \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: out of memory"
          ]
        }
      ],
      "source": [
        "seq_len = 40         # BPTT length\n",
        "n_epochs = 1\n",
        "learning_rate = 1e-3\n",
        "weight_decay = 0.0\n",
        "clip = 0.25\n",
        "\n",
        "start_time = time.time()\n",
        "train_acc, train_loss = train_wikitext(\n",
        "    transformer_lm,\n",
        "    train_data,\n",
        "    seq_len=seq_len,\n",
        "    n_epochs=n_epochs,\n",
        "    optimizer=ndl.optim.SGD,   # or ndl.optim.Adam\n",
        "    lr=learning_rate,\n",
        "    weight_decay=weight_decay,\n",
        "    loss_fn=nn.SoftmaxLoss,\n",
        "    clip=clip,\n",
        "    device=device,\n",
        "    dtype=\"float32\",\n",
        ")\n",
        "end_time = time.time()\n",
        "\n",
        "print(f\"Training finished in {end_time - start_time:.2f} seconds.\")\n",
        "print(f\"Final train loss: {train_loss:.4f}, train acc: {train_acc:.4f}\")\n",
        "print(f\"Train perplexity: {math.exp(train_loss):.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "y7RTUJ3S2JRj",
      "metadata": {
        "id": "y7RTUJ3S2JRj"
      },
      "source": [
        "## Evaluate on validation and test -- transformer_lm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kuIcA1jx2JRk",
      "metadata": {
        "id": "kuIcA1jx2JRk"
      },
      "outputs": [],
      "source": [
        "val_acc, val_loss = evaluate_wikitext(\n",
        "    transformer_lm,\n",
        "    valid_data,\n",
        "    seq_len=seq_len,\n",
        "    loss_fn=nn.SoftmaxLoss,\n",
        "    device=device,\n",
        "    dtype=\"float32\",\n",
        ")\n",
        "print(f\"Valid loss: {val_loss:.4f}, valid acc: {val_acc:.4f}\")\n",
        "print(f\"Valid perplexity: {math.exp(val_loss):.4f}\")\n",
        "\n",
        "test_acc, test_loss = evaluate_wikitext(\n",
        "    transformer_lm,\n",
        "    test_data,\n",
        "    seq_len=seq_len,\n",
        "    loss_fn=nn.SoftmaxLoss,\n",
        "    device=device,\n",
        "    dtype=\"float32\",\n",
        ")\n",
        "print(f\"Test loss: {test_loss:.4f}, test acc: {test_acc:.4f}\")\n",
        "print(f\"Test perplexity: {math.exp(test_loss):.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PT7h62RqGq46",
      "metadata": {
        "id": "PT7h62RqGq46"
      },
      "source": [
        "## Train on WikiText-103 -- transformer_moe\n",
        "\n",
        "Call `train_wikitext` function from `apps/simple_ml.py`.\n",
        "Feel free to tweak `n_epochs`, `lr`, optimizer, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Q76PLlvOGqqs",
      "metadata": {
        "id": "Q76PLlvOGqqs"
      },
      "outputs": [],
      "source": [
        "seq_len = 40         # BPTT length\n",
        "n_epochs = 1\n",
        "learning_rate = 1e-3\n",
        "weight_decay = 0.0\n",
        "clip = 0.25\n",
        "\n",
        "start_time = time.time()\n",
        "train_acc, train_loss = train_wikitext(\n",
        "    transformer_moe,\n",
        "    train_data,\n",
        "    seq_len=seq_len,\n",
        "    n_epochs=n_epochs,\n",
        "    optimizer=ndl.optim.SGD,   # or ndl.optim.Adam\n",
        "    lr=learning_rate,\n",
        "    weight_decay=weight_decay,\n",
        "    loss_fn=nn.SoftmaxLoss,\n",
        "    clip=clip,\n",
        "    device=device,\n",
        "    dtype=\"float32\",\n",
        ")\n",
        "end_time = time.time()\n",
        "\n",
        "print(f\"Training finished in {end_time - start_time:.2f} seconds.\")\n",
        "print(f\"Final train loss: {train_loss:.4f}, train acc: {train_acc:.4f}\")\n",
        "print(f\"Train perplexity: {math.exp(train_loss):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6TrLW_GeG9kE",
      "metadata": {
        "id": "6TrLW_GeG9kE"
      },
      "source": [
        "## Evaluate on validation and test -- transformer_moe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BDmwP6RbGqon",
      "metadata": {
        "id": "BDmwP6RbGqon"
      },
      "outputs": [],
      "source": [
        "val_acc, val_loss = evaluate_wikitext(\n",
        "    transformer_moe,\n",
        "    valid_data,\n",
        "    seq_len=seq_len,\n",
        "    loss_fn=nn.SoftmaxLoss,\n",
        "    device=device,\n",
        "    dtype=\"float32\",\n",
        ")\n",
        "print(f\"Valid loss: {val_loss:.4f}, valid acc: {val_acc:.4f}\")\n",
        "print(f\"Valid perplexity: {math.exp(val_loss):.4f}\")\n",
        "\n",
        "test_acc, test_loss = evaluate_wikitext(\n",
        "    transformer_moe,\n",
        "    test_data,\n",
        "    seq_len=seq_len,\n",
        "    loss_fn=nn.SoftmaxLoss,\n",
        "    device=device,\n",
        "    dtype=\"float32\",\n",
        ")\n",
        "print(f\"Test loss: {test_loss:.4f}, test acc: {test_acc:.4f}\")\n",
        "print(f\"Test perplexity: {math.exp(test_loss):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "y0WTdHBVGqlP",
      "metadata": {
        "id": "y0WTdHBVGqlP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bqiDFh95GqjI",
      "metadata": {
        "id": "bqiDFh95GqjI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oUiKxvT9GqSS",
      "metadata": {
        "id": "oUiKxvT9GqSS"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
